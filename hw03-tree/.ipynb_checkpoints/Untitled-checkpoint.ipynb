{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./cs-training.csv', sep=',').dropna()\n",
    "\n",
    "x = df.as_matrix(columns=df.columns[1:])\n",
    "y = df.as_matrix(columns=df.columns[:1])\n",
    "y = y.reshape(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyDecisionTreeClassifier:\n",
    "#     NON_LEAF_TYPE = 0\n",
    "#     LEAF_TYPE = 1\n",
    "\n",
    "#     def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "#         self.tree = dict()\n",
    "#         self.min_samples_split = min_samples_split\n",
    "#         self.max_depth = max_depth\n",
    "#         self.sufficient_share = sufficient_share\n",
    "#         self.num_class = -1\n",
    "#         if criterion == 'gini':\n",
    "#             self.G_function = self.__gini\n",
    "#         elif criterion == 'entropy':\n",
    "#             self.G_function = self.__entropy\n",
    "#         elif criterion == 'misclass':\n",
    "#             self.G_function = self.__misclass\n",
    "#         else:\n",
    "#             print 'invalid criterion name'\n",
    "#             raise\n",
    "\n",
    "#         if max_features == 'sqrt':\n",
    "#             self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "#         elif max_features == 'log2':\n",
    "#             self.get_feature_ids = self.__get_feature_ids_log2\n",
    "#         elif max_features == None:\n",
    "#             self.get_feature_ids = self.__get_feature_ids_N\n",
    "#         else:\n",
    "#             print 'invalid max_features name'\n",
    "#             raise\n",
    "\n",
    "#     def __gini(self, l_c, l_s, r_c, r_s):\n",
    "#         l_s = l_s.astype('float')\n",
    "#         r_s = r_s.astype('float')\n",
    "#         return # Ваш код\n",
    "    \n",
    "#     def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "#         return # Ваш код \n",
    "\n",
    "#     def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "#         return # Ваш код\n",
    "\n",
    "#     def __get_feature_ids_sqrt(self, n_feature):\n",
    "#         feature_ids = range(n_feature)\n",
    "#         np.random.shuffle(feature_ids)\n",
    "#         return # Ваш код\n",
    "        \n",
    "#     def __get_feature_ids_log2(self, n_feature):\n",
    "#         feature_ids = range(n_feature)\n",
    "#         np.random.shuffle(feature_ids)\n",
    "#         return # Ваш код\n",
    "\n",
    "#     def __get_feature_ids_N(self, n_feature):\n",
    "#         return # Ваш код\n",
    "    \n",
    "#     def __sort_samples(self, x, y):\n",
    "#         sorted_idx = x.argsort()\n",
    "#         print y.shape\n",
    "#         return NULL\n",
    "#         return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "#     def __div_samples(self, x, y, feature_id, threshold):\n",
    "#         left_mask = x[:, feature_id] > threshold\n",
    "#         right_mask = ~left_mask\n",
    "#         return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "#     def find_threshold(self, x, y):\n",
    "#         # Что делает этот блок кода?    \n",
    "#         #  Переупорядочиваем элементы \n",
    "#         sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "#         print sorted_y\n",
    "#         class_number = np.unique(y).shape[0]\n",
    "        \n",
    "#         # Что делает этот блок кода?\n",
    "#         splitted_sorted_y = sorted_y[self.min_samples_split:-self.min_samples_split]\n",
    "#         r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "        \n",
    "#         if len(r_border_ids) == 0:\n",
    "#             return float('+inf'), None\n",
    "        \n",
    "#         # Что делает этот блок кода?\n",
    "#         eq_el_count = r_border_ids - np.append([self.min_samples_split], r_border_ids[:-1])\n",
    "#         one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        \n",
    "#         one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "#         class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "#         class_increments[0] = class_increments[0] + np.bincount(sorted_y[:self.min_samples_split], minlength=class_number)\n",
    "        \n",
    "#         # Что делает этот блок кода?\n",
    "#         l_class_count = np.cumsum(class_increments, axis=0)        \n",
    "#         r_class_count = np.bincount(y) - l_class_count\n",
    "#         l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "#         r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "#         # Что делает этот блок кода?\n",
    "#         gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "#         idx = np.argmin(gs)\n",
    "    \n",
    "#         # Что делает этот блок кода?\n",
    "#         left_el_id = l_sizes[idx][0]\n",
    "#         return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "#     def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "#         # Ваш код\n",
    "#         # Необходимо использовать следующее:\n",
    "#         # self.LEAF_TYPE\n",
    "#         # self.NON_LEAF_TYPE\n",
    "\n",
    "#         # self.tree\n",
    "#         # self.max_depth\n",
    "#         # self.sufficient_share\n",
    "#         # self.min_samples_split\n",
    "\n",
    "#         # self.get_feature_ids\n",
    "#         # self.__find_threshold\n",
    "#         # self.__div_samples\n",
    "#         # self.__fit_node\n",
    "#         pass\n",
    "    \n",
    "#     def fit(self, x, y):\n",
    "#         self.num_class = np.unique(y).size\n",
    "#         self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "#     def __predict_class(self, x, node_id):\n",
    "#         node = self.tree[node_id]\n",
    "#         if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "#             _, feature_id, threshold = node\n",
    "#             if x[feature_id] > threshold:\n",
    "#                 return self.__predict_class(x, 2 * node_id + 1)\n",
    "#             else:\n",
    "#                 return self.__predict_class(x, 2 * node_id + 2)\n",
    "#         else:\n",
    "#             return node[1]\n",
    "\n",
    "#     def __predict_probs(self, x, node_id):\n",
    "#         node = self.tree[node_id]\n",
    "#         if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "#             _, feature_id, threshold = node\n",
    "#             if x[feature_id] > threshold:\n",
    "#                 return self.__predict_probs(x, 2 * node_id + 1)\n",
    "#             else:\n",
    "#                 return self.__predict_probs(x, 2 * node_id + 2)\n",
    "#         else:\n",
    "#             return node[2]\n",
    "        \n",
    "#     def predict(self, X):\n",
    "#         return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "#     def predict_probs(self, X):\n",
    "#         return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "#     def fit_predict(self, x_train, y_train, predicted_x):\n",
    "#         self.fit(x_train, y_train)\n",
    "#         return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print 'invalid criterion name'\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print 'invalid max_features name'\n",
    "            raise\n",
    "    \n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        '''\n",
    "        Calculates gini impurity\n",
    "\n",
    "        For each function calculating following: |S_l| * I(S_l) + |S_r| * I(S_r),\n",
    "        where |S| is capacity of data S and I(S) is actual impurity function\n",
    "        '''\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        I_left = (1.0 - np.sum((l_c/l_s)**2, axis=1)).reshape(-1,1)*l_s\n",
    "        I_right = (1.0 - np.sum((r_c/r_s)**2, axis=1)).reshape(-1,1)*r_s\n",
    "        gini = I_left + I_right\n",
    "        return gini\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        '''\n",
    "        Calculates entropy impurity\n",
    "        '''\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        # using epsilon and np.clip() to avoid zeros in logarith function\n",
    "        eps = 0.0001\n",
    "        to_log_l = np.clip((l_c/l_s),  eps, 1-eps)\n",
    "        to_log_r = np.clip((r_c/r_s), eps, 1-eps)\n",
    "        I_left = -np.sum((l_c/l_s)*np.log2(to_log_l), axis=1).reshape(-1,1)*l_s\n",
    "        I_right = -np.sum((r_c/r_s)*np.log2(to_log_l), axis=1).reshape(-1,1)*r_s\n",
    "        entropy = I_left + I_right\n",
    "        return entropy\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        '''\n",
    "        Calculates misclass impurity function\n",
    "        '''\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        I_l = (1.0 - np.max((l_c/l_s), axis=1)).reshape(-1,1)*l_s\n",
    "        I_r = (1.0 - np.max((r_c/r_s), axis=1)).reshape(-1,1)*r_s\n",
    "        misclass = I_l + I_r\n",
    "        return misclass\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[0:int(np.sqrt(n_feature))]\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[0:int(np.log2(n_feature))]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids\n",
    "    \n",
    "    def sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # this code sorts specific column from features matrix in ascending order \n",
    "        # and lets us obtain target features' vector (TFV) in the same order,\n",
    "        # than it stores the number of unique values in target vector to the 'class_number\" variable \n",
    "        sorted_x, sorted_y = self.sort_samples(x, y)\n",
    "        return self.sort_samples(x,y)\n",
    "        return NULL\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        \n",
    "        # this code takes the slice of sorted TFV cutting first min_samples elements and last min_samples elements\n",
    "        # than it stores absolute indices in cut sorted TFV where values differ from previous values\n",
    "        splitted_sorted_y = sorted_y[self.min_samples_split:-self.min_samples_split]\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "        \n",
    "        # if all values in cutted sorted TFV are the same or if cut sorted TFE is empty returns (+inf, None)\n",
    "        if len(r_border_ids) == 0:\n",
    "            return float('+inf'), None\n",
    "        # if not then continue processing\n",
    "        \n",
    "        # this code stores in eq_el_count numbers of the groups of equal values (GEV) in cut sorted TFV \n",
    "        # before the last change without length of last group;\n",
    "        # than it creates matrix which rows correspond to each GEV and columns correspond to value of GEV,\n",
    "        # in cells of this matrix are lengths of GEV;\n",
    "        # at last it appends for the first row of this matrix number of zeros and ones in (not sorted???)\n",
    "        # TFV before the left split border\n",
    "        \n",
    "        eq_el_count = r_border_ids - np.append([self.min_samples_split], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:self.min_samples_split], minlength=class_number)\n",
    "        \n",
    "        # this code creates four structures:\n",
    "        # l_class_count and r_class_count stores matrices in which rows are values of counts of elements zeros and ones\n",
    "        # from the left and from the right respectively\n",
    "        # l_sizes, r_sizes stores count of elements of each group (for each row in matrix) also respectively\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)        \n",
    "        r_class_count = np.bincount(y) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # than it calculates criteria function for the given data and obtains values for each threshold\n",
    "        # and stores the id of the minimum of criteria function vector\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "    \n",
    "        # now it takes the id of data using id of minimum and returns minimum value of criteria function vector\n",
    "        # and the mean of two  elements of data between which threshold passed\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        '''\n",
    "        Recursive function that fills decision tree structure.\n",
    "        Leaf nodes contains: (leaf flag, main class of this node, share of this class in the node)\n",
    "        Non leaf node contains: (non leaf flag, splitting feature, threshold)\n",
    "        '''\n",
    "        # This code gives count of samples in current X on this step of reccursion and calculates\n",
    "        # the share of each class of target feature in current Y\n",
    "        samples_count = x.shape[0]\n",
    "        classes, class_counts = np.unique(y, return_counts=True)\n",
    "        class_probs = class_counts.astype('float') / samples_count\n",
    "        cl_idx = np.argmax(class_probs)\n",
    "\n",
    "        # Create leaf node if depth is enough\n",
    "        if (depth >= self.max_depth) and (self.max_depth is not None):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, classes[cl_idx], class_probs[cl_idx])\n",
    "            return\n",
    "        \n",
    "        # Create leaf node count in X is too short\n",
    "        if (samples_count <= self.min_samples_split):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, classes[cl_idx], class_probs[cl_idx])\n",
    "            return\n",
    "          \n",
    "        # Create leaf node if the share of any class is enough\n",
    "        if (class_probs[cl_idx] >= self.sufficient_share):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, classes[cl_idx], class_probs[cl_idx])\n",
    "            return\n",
    "        \n",
    "        # Get features by rule and find the best feature to split with threshold\n",
    "        n_features = x.shape[1]\n",
    "        all_gs_threshold = np.zeros((n_features, 2))\n",
    "        for idx in self.get_feature_ids(n_features):\n",
    "            print idx\n",
    "            all_gs_threshold[idx,:] = self.__find_threshold(x[:,idx],y)\n",
    "            \n",
    "        best_feature_id = np.argmin(all_gs_threshold[:,0])\n",
    "        \n",
    "        # if threshold is inf then create leaf node\n",
    "        if np.min(all_gs_threshold[:,0]) == float('+inf'):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, classes[cl_idx], class_probs[cl_idx])\n",
    "            return \n",
    "        # Split data by feature and threshold\n",
    "        threshold = all_gs_threshold[best_feature_id][1]\n",
    "        x_l, x_r, y_l, y_r = self.__div_samples(x, y, best_feature_id, threshold)\n",
    "        \n",
    "        # If the best split is when one half contains all of the given data then create leaf node without splitting\n",
    "        if (len(y_l) == 0) or (len(y_r) == 0):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, classes[cl_idx], class_probs[cl_idx])\n",
    "            return\n",
    "        \n",
    "        # In other cases create a non leaf node which contains feat_id and threshold\n",
    "        self.tree[node_id] = (self.NON_LEAF_TYPE, best_feature_id, threshold,)\n",
    "        \n",
    "        # value > threshold goes left\n",
    "        # Call that function for left and right parts of splitted data\n",
    "        self.__fit_node(x_l, y_l, 2*node_id+1, depth+1)\n",
    "        self.__fit_node(x_r, y_r, 2*node_id+2, depth+1)\n",
    "        \n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "a, b = my_clf.sort_samples(x,y)\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-af3c9c3a51e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-144-3aee1eeb2b9b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fit_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__predict_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-144-3aee1eeb2b9b>\u001b[0m in \u001b[0;36m__fit_node\u001b[0;34m(self, x, y, node_id, depth, pred_f)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mall_gs_threshold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__find_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mbest_feature_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_gs_threshold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "c, d = my_clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
