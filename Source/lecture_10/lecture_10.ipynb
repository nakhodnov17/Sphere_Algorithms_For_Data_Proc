{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/header.png\">\n",
    "\n",
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "\n",
    "## Лекция 10. Data Mining в реальных системах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Сегодня на лекции\n",
    "\n",
    "* Работа с признаками\n",
    "* Алгоритмы машинного обучения\n",
    "* Особенности реальных систем\n",
    "* Что дальше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Работа с признаками\n",
    "### Конструирование признаков\n",
    "\n",
    "Лог посещения пользователями Интернет-сайтов\n",
    "\n",
    "1432068600.002494\n",
    "46.148.52.217\n",
    "22B695259\n",
    "22/159/5/0/0/6/1/1.000000/16.0\n",
    "2579437\n",
    "http://vk.com/ivan_se\n",
    "http://vk.com/friends?act=find\n",
    "1152*864\n",
    "1137*747\n",
    "1432068601241\n",
    "Поиск друзей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Преобразование признаков\n",
    "* Дискретизация\n",
    "* Проекции\n",
    "  * PCA\n",
    "  * Random projections\n",
    "* Заполнение отсутствующих значений\n",
    "* Удаление шума\n",
    "* Преобразование категориальных классов в бинарные\n",
    "  * One-vs-rest\n",
    "  * One-vs-one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Отбор признаков\n",
    "Как “нерелевантные”, так и “релевантные” признаки могут быть вредными\n",
    "1. Независимо от алгоритма обучения: backward elimination, forward selection\n",
    "  * mutual information\n",
    "  * коэффициент корреляции\n",
    "  * линейная модель\n",
    "  * генетические алгоритмы\n",
    "2. С использованием алгоритма обучения\n",
    "  (кросс-валидация, hold-out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Forward selection, which involves starting with no variables in the model, testing the addition of each variable using a chosen model fit criterion, adding the variable (if any) whose inclusion gives the most statistically significant improvement of the fit, and repeating this process until none improves the model to a statistically significant extent.  \n",
    "\n",
    "Backward elimination, which involves starting with all candidate variables, testing the deletion of each variable using a chosen model fit criterion, deleting the variable (if any) whose loss gives the most statistically insignificant deterioration of the model fit, and repeating this process until no further variables can be deleted without a statistically significant loss of fit.  \n",
    "\n",
    "Bidirectional elimination, a combination of the above, testing at each step for variables to be included or excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Алгоритмы машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Некоторые правила 1\n",
    "\n",
    "Первое правило машинного обучения\n",
    "  *Если нет необходимости, не использовать машинное обучение*\n",
    "  \n",
    "  \n",
    "[Второе правило машинного обучения](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)\n",
    "\n",
    "LEARNING =\n",
    "  REPRESENTATION + EVALUATION + OPTIMIZATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Некоторые правила 2\n",
    "\n",
    "* Интуиция подводит в многомерных пространствах\n",
    "* Больше данных лучше, чем сложный алгоритм\n",
    "* Обучайте много моделей\n",
    "\n",
    "<img src=\"images/netfilx.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Все модели имеют недостатки](http://web.archive.org/web/20140326142656/http://hunch.net/?p=224)\n",
    "\n",
    "|Подход | Что хорошо | Что плохо | \n",
    "|---|---|---|\n",
    "|bayesian learning | хорошо работает на маленьких данных | трудно обосновать априорные распрделения, вычислительно сложные |  \n",
    "|градиентный спуск | вычислительно эффективен, оптимизируем что нужно | подбор параметров для сходимости, переобучение |  \n",
    "|kernel | натуральное выражение схожести через ядро | подбор ядра, медленный |  \n",
    "|деревья решений | быстрый и автоматизированный | крайне нестабильный |  \n",
    "|boosting | хорошее качество | выбор алгоритма, предположение о weak learner нарушается  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [8 худших алгоритмов](http://www.analyticbridge.com/profiles/blogs/the-8-worst-predictive-modeling-techniques)\n",
    "\n",
    "* Linear regression\n",
    "* Traditional decision trees\n",
    "* Linear discriminant analysis\n",
    "* K-means clustering\n",
    "* Neural networks\n",
    "* Maximum Likelihood estimation\n",
    "* Density estimation in high dimensions\n",
    "* Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Отбор модели занимает очень много времени](http://blog.mikiobraun.de/2015/03/three-things-about-data-science.html)\n",
    "\n",
    "<img src=\"images/evaluation.png\">\n",
    "\n",
    "(также, как и работа с признаками)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Особенности реальных систем\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Пример обучения модели в задаче классификации\n",
    "\n",
    "<img src=\"images/podelie.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Особенности реальной системы\n",
    "\n",
    "* Очень грязные данные\n",
    "* Простые модели\n",
    "* Проверка качества на всех этапах\n",
    "* Мониторинг и логирование\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Что дальше\n",
    "\n",
    "### Изучение Data Mining\n",
    "\n",
    "1. Data Mining II, Hadoop, Инфопоиск\n",
    "2. Kaggle\n",
    "3. Литература и статьи\n",
    "\n",
    "\n",
    "* [Техблог Twitter](https://blog.twitter.com/engineering)\n",
    "* [Техблог Netflix](http://techblog.netflix.com/?m=1)\n",
    "* [Техблог Spotify](https://labs.spotify.com/)\n",
    "* [Reddit про MachineLearning](http://www.reddit.com/r/MachineLearning/)\n",
    "* [Подкаст про машинное обучение](http://www.thetalkingmachines.com/)\n",
    "* [DataViz](http://flowingdata.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Junior Data Scientist: необходимые навыки\n",
    "\n",
    "* Все базовые модели и алгоритмы\n",
    "* Знание языка высокого уровня и соответствующие научные библиотеки \\\\ (R, python, Matlab)\n",
    "* Базовые структуры данных и алгоритмы \\\\ (сортировки, деревья, хэш таблицы и графы)\n",
    "* Опыт обработки больших объемов данных точно будет плюсом\n",
    "* Умение разбираться с научной литературой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/sklearn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Вопросы"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
